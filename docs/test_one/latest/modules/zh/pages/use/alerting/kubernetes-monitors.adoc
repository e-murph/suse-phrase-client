= 监视器
:revdate: 2025-07-10
:page-revdate: {revdate}
:description: SUSE 可观察性

== 概述

本节介绍随 SUSE Observability 提供的开箱即用监控器。随产品交付的监视器不断增加。请在主菜单的 "显示器 "部分查看完整列表。

== 开箱即用的 Kubernetes 监控程序

=== 可用服务端点

必须确保您的服务可供用户使用和访问。为了监控这一点，SUSE Observability 设置了一项检查，以验证服务是否至少有一个端点可用。端点是实现分布式系统中不同组件之间通信的网络地址，它们必须可用，服务才能正常运行。
如果在过去 10 分钟内出现可用端点为零的情况，监控器将保持偏离，表明服务可能存在问题，需要解决。
允许xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖监控器参数]

=== Cpu 限制 资源配额

用户在命名空间中创建资源（pod、服务等），配额系统会跟踪使用情况，确保不超过 ResourceQuota 中定义的 Cpu 硬资源限制。当命名空间的总 Cpu 限制达到或超过配额规定的 90% 时，监控器就会发出警报。命名空间中的每个`resourcequota` 都会产生一个监控器健康状态。

=== CPU 请求资源配额

用户在命名空间中创建资源（pod、服务等），配额系统会跟踪使用情况，确保不超过 ResourceQuota 中定义的 Cpu 硬资源请求。当命名空间中的总 Cpu 请求达到或超过配额规定的 90% 时，监控器就会发出警报。命名空间中的每个`resourcequota` 都会产生一个监控器健康状态。

=== 所需的 Daemonset 复制

重要的是，要满足 Daemonset 所需的副本数量。Daemonsets 用于管理一组需要在集群中所有节点或部分节点上运行的 pod，确保每个节点上都有符合指定条件的 pod 副本在运行。这对于日志记录、监控和其他需要在集群中每个节点上执行的集群级任务非常有用。

为了监控这一点，SUSE Observability 设置了一项检查，以验证可用副本是否与所需副本数量相匹配。该检查只会应用于所需复制数大于零的 DaemonSets。

* 如果可用副本的数量少于预期数量，监控器就会发出 "DEVIATING "健康状态信号，表明状态集可能存在问题。
* 如果可用副本的数量为零，监控器将发出 CRITICAL 健康状态信号，表明 StatefulSet 完全无法运行。

要了解完整的监控器定义，请查看详细信息。

=== 磁盘空间偏差

随着时间的推移，监控 Kubernetes 集群中持久卷声称 (PVC) 的使用情况非常重要。PVC 用于存储需要在容器生命周期之后持续存在的数据，因此确保它们有足够的空间来存储数据至关重要。
为了跟踪这一点，我们设置了一个检查，使用线性预测来预测 4 天内 Kubernetes 的使用量趋势。如果趋势显示 PVC 将在此时间范围内耗尽空间，您将收到通知，以便采取措施防止数据丢失或停机。

=== 磁盘空间至关重要

监控 Kubernetes 集群中持久卷声称 (PVC) 的使用情况非常重要。PVC 用于存储需要在容器生命周期之后持续存在的数据，因此确保它们有足够的空间来存储数据至关重要。为了跟踪这一点，我们设置了一个检查，使用线性预测来预测 12 小时内 Kubernetes 的容量使用趋势。如果趋势显示 PVC 将在此时间范围内耗尽空间，您将收到通知，以便采取措施防止数据丢失或停机。

=== 部署所需的副本

满足部署所需的副本数量非常重要。部署用于管理 Kubernetes 集群中一组相同 Pod 的部署和扩展。通过确保所需数量的副本正在运行并可用，部署可以帮助维持 Kubernetes 应用程序或服务的可用性和可靠性。为了监控这一点，SUSE Observability 设置了一项检查，以验证可用副本是否与所需副本数量相匹配。

此检查只会应用于所需复制数量大于零的部署。

* 如果可用副本的数量少于所需的数量，监控器将发出 DEVIATING 健康状态信号，表明部署可能存在问题。
* 如果可用副本的数量为零，监控器将发出 CRITICAL 健康状态信号，表明 StatefulSet 完全无法运行。

要了解完整的监控器定义，请查看详细信息。

=== HTTP - 5xx 错误率

状态代码在 5xx 范围内的 HTTP 响应表示服务器端错误，如配置错误、过载或服务器内部错误。
为确保良好的用户体验，5xx 响应的百分比应低于 Kubernetes 服务 HTTP 响应总数的 5%。

由于确切的阈值和严重程度可能取决于应用，因此可以xref:/use/alerting/k8s-override-monitor-arguments.adoc[通过]服务上的xref:/use/alerting/k8s-override-monitor-arguments.adoc[Kubernetes 注释来重写阈值]。例如，要覆盖预配置的偏差阈值，而只将临界阈值设定为 6%，请在服务上添加此注释：
```
monitor.kubernetes-v2.stackstate.io/http-error-ratio-for-service: | 
  { 
    "criticalThreshold": 0.06,
    "deviatingThreshold": null
  }
```

如果从该 json 代码段中省略偏离阈值，则会将其保持在配置的 5%，而临界阈值为 6%，这意味着监控器只会在误差比在 5%和 6%之间时才会出现偏离状态。

=== HTTP - 响应时间 - Q95 超过 3 秒

跟踪 Kubernetes 服务的第 95 百分位数 (Q95) HTTP 响应时间可帮助您发现可能影响用户的缓慢请求和性能异常值。如果 Q95 的响应时间在指定时间窗口内超过 3 秒，监视器将发出偏离状态警报。

您可以使用服务上的 Kubernetes 注释来xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖默认设置]（如时间窗口、阈值或量化值），从而根据应用程序的需要定制该监控器。如果您的服务有独特的性能要求，这种灵活性将非常有用。例如，长期轮询服务。

要自定义监控器，请在服务中添加如下注释，并根据需要调整数值：

```
monitor.kubernetes-v2.stackstate.io/http-response-time/overrides: |
  {
    "deviatingTimeWindow": "10m",            // Time window for a deviating state (e.g., "10m", "1h")
    "deviatingThreshold": 1.2,               // Threshold in seconds for a deviating state
    "criticalTimeWindow": "30m",             // Time window for a critical state
    "criticalThreshold": 2.0,                // Threshold in seconds for a critical state
    "quantile": 0.99,                        // Quantile to monitor (e.g., 0.95, 0.99)
    "nameTemplate": "API latency (p{{ quantile }}) > {{ threshold }}", // Custom monitor name
    "enabled": true                          // Set to false to disable this monitor for the service
  }
```

- 您可以省略任何字段，使用其默认值。
- 监控器会在指定窗口内评估所选响应时间的量化值。如果数值高于阈值，监控器就会触发。
- 在上例中，如果第 99 百分位数 (Q99) 响应时间超过 1.2 秒（过去 10 分钟），监控器将发出偏离状态信号；如果超过 2.0 秒（过去 30 分钟），监控器将发出临界状态信号。

=== 12 小时内 Kubernetes 容量使用趋势

监控 Kubernetes 集群中持久卷声称 (PVC) 的使用情况非常重要。PVC 用于存储需要在容器生命周期之后持续存在的数据，因此确保它们有足够的空间来存储数据至关重要。为了跟踪这一点，SUSE Observability 设置了一项检查，使用线性预测来预测 12 小时内 Kubernetes 的容量使用趋势。如果趋势显示 PVC 将在此时间范围内耗尽空间，您将收到通知，以便采取措施防止数据丢失或停机。

=== Kubernetes 4 天内的使用量趋势

随着时间的推移，监控 Kubernetes 集群中持久卷声称 (PVC) 的使用情况非常重要。PVC 用于存储需要在容器生命周期之后持续存在的数据，因此确保它们有足够的空间来存储数据至关重要。
为了跟踪这一点，SUSE Observability 设置了一项检查，使用线性预测来预测 Kubernetes 在 4 天内的容量使用趋势。如果趋势显示 PVC 将在此时间范围内耗尽空间，您将收到通知，以便采取措施防止数据丢失或停机。

=== 内存限制 resourcequota

用户在命名空间中创建资源（pod、服务等），配额系统会跟踪使用情况，确保不超过 ResourceQuota 中定义的内存硬资源限制。当命名空间的总内存限制达到或超过配额规定的 90% 时，监控器就会发出警报。命名空间中的每个`resourcequota` 都会产生一个监控器健康状态。

=== 内存请求 资源配额

用户在命名空间中创建资源（pod、服务等），配额系统会跟踪使用情况，确保不超过 ResourceQuota 中定义的内存硬资源请求。当命名空间的总内存请求达到或超过配额规定的 90% 时，监控器就会发出警报。命名空间中的每个`resourcequota` 都会产生一个监控器健康状态。

=== 节点磁盘压力

节点磁盘压力是指连接到节点的磁盘承受过大应变的情况。虽然由于 Kubernetes 内置的预防措施，遇到节点磁盘压力的可能性不大，但这种情况仍可能偶尔发生。出现节点盘压力的主要原因有两个。第一个原因与 Kubernetes 未能清理未使用的映像有关。在正常情况下，Kubernetes 会定期检查并删除不使用的映像。因此，这是造成结节盘压力的一个不常见原因，但应该得到承认。更有可能的问题涉及日志的积累。在 Kubernetes 中，日志通常在两种情况下保存：容器运行时和为故障排除目的保留最近退出的容器日志时。这种方法的目的是在保留重要日志和随着时间推移丢弃不必要日志之间取得平衡。但是，如果一个长期运行的容器产生大量日志，它们可能会累积到使节点磁盘的容量超载的程度。要了解完整的监控器定义，请查看详细信息。
允许xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖监控器参数]

=== 节点内存压力

节点内存压力是指 Kubernetes 节点上的内存资源过度紧张的情况。虽然由于 Kubernetes 内置的资源管理机制，遇到节点内存压力的情况并不常见，但在特定情况下仍有可能发生。出现节点记忆压力的主要原因有两个。第一个原因与节点上运行的容器的资源请求和限制配置错误或不足有关。Kubernetes 依靠资源请求和限制来有效分配和管理资源。如果没有准确配置容器的内存需求，它们可能会消耗比预期更多的内存，从而导致节点内存压力。第二个原因涉及内存密集型应用程序或进程的存在。某些工作负载或应用可能对内存有更高的要求，从而导致节点的内存利用率增加。如果在没有适当资源分配的情况下，在同一节点上调度多个需要大量内存的 pod 或容器，就会造成内存压力。要减轻节点内存压力，关键是要审查和调整容器的资源请求和限制，确保它们与应用程序的实际内存需求相一致。监控和优化应用程序本身的内存使用情况也有助于减少内存消耗。此外，还可以考虑水平 pod 自动扩展，以便根据内存利用率动态扩展 pod 的数量。定期监控、分析内存相关指标并主动分配内存资源，有助于在 Kubernetes 节点上保持健康的内存状态。必须了解工作负载的具体要求，并相应调整资源分配，以防止内存压力并确保最佳性能。
允许xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖监控器参数]

=== 节点 PID 压力

当 Kubernetes 节点上的可用进程标识（PID）资源过度紧张时，就会出现节点 PID 压力。第一个原因与节点上运行的容器的资源请求和限制配置错误或不足有关。Kubernetes 依靠准确的资源请求和限制来有效分配和管理资源。如果容器的 PID 需求配置不正确，它们可能会消耗比预期更多的 PID，从而造成节点 PID 压力。第二个原因是存在 PID 密集型应用程序或进程。某些工作负载或应用对进程识别的要求更高，导致节点上的 PID 利用率增加。如果在没有适当资源分配的情况下，在同一节点上调度多个需要大量 PID 的 pod 或容器，就会造成 PID 压力。为了应对节点 PID 压力，必须审查和调整容器的资源请求和限制，以确保它们与应用程序的实际 PID 需求保持一致。监控和优化应用程序本身的 PID 使用也有助于减少 PID 消耗。此外，考虑到水平 pod 自动伸缩，可以根据 PID 利用率动态缩放 pod 的数量。定期监控、分析 PID 相关指标以及主动分配 PID 资源，对于维持 Kubernetes 节点上 PID 使用的健康状态至关重要。必须了解工作负载的具体要求，并相应调整资源分配，以防止 PID 压力并确保最佳性能。
允许xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖监控器参数]

=== 节点就绪

检查节点是否按预期启动和运行。
允许xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖监控器参数]

=== 孤立的持久卷

确认没有持久卷成为孤儿。无主持久加密卷是指未与持久加密卷要求相关联的持久加密卷。无主持久卷可能存在安全风险，因为其中可能包含未被使用的敏感数据。无主持久卷也会浪费资源，因为它没有被使用。
允许xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖监控器参数]，但只有`enabled` 属性

=== 容器内存不足

必须确保 Kubernetes 集群中运行的容器有足够的内存来正常运行。内存不足（OOM）情况会导致容器崩溃或反应迟钝，从而导致重启和潜在的数据丢失。
为了监控这些情况，SUSE Observability 设置了一项检查，用于检测和报告集群中运行的容器中的 OOM 事件。这项检查将帮助你识别任何正在耗尽内存的容器，并允许你采取行动，防患于未然。
允许xref:/use/alerting/k8s-override-monitor-arguments.adoc[覆盖监控器参数]

=== Pod 就绪状态

检查已调度的 Pod 是否正在运行，是否已准备好在预期时间内接收流量。

=== 波德跨度持续时间

监控服务器和用户跨度的持续时间。当持续时间的第 95 百分位数大于阈值（默认为 5000 毫秒）时，监视器处于偏离状态。该监视器支持通过xref:/use/alerting/k8s-override-monitor-arguments.adoc[监视器参数重载]来覆盖设置。

=== 波德跨度误差比

监控出现错误状态的服务器和用户跨度的百分比。如果错误跨度百分比超过阈值（默认值 5），则监视器处于偏离状态。该监视器支持通过xref:/use/alerting/k8s-override-monitor-arguments.adoc[监视器参数重载]来覆盖设置。

=== 处于等待状态的舱体

如果 pod 处于等待状态，且包含 CreateContainerConfigError、CreateContainerError、CrashLoopBackOff 或 ImagePullBackOff 等原因，则会被视为偏离。

=== 所需的副本集

确保满足副本集（和部署）所需的副本数量非常重要。副本集和部署用于管理 Kubernetes 集群中特定 pod 的副本数量。

为了监控这一点，SUSE Observability 设置了一项检查，以验证可用副本是否与所需副本数量相匹配。此检查只会应用于所需副本数量大于零的副本集和部署。

* 如果可用副本的数量少于预期数量，监控器将发出 DEVIATING 健康状态信号，表明副本集或部署可能存在问题。
* 如果可用副本的数量为零，监控程序将发出 CRITICAL 健康状态信号，表明副本集或部署完全无法运行。

此外，副本集的健康状态将传播到部署，以便进行更全面的监控。

=== 重新启动容器

监控 Kubernetes 集群中每个容器的重新启动非常重要。容器重启的原因有很多，包括应用程序或基础设施的问题。
为确保应用程序顺利运行，SUSE Observability 设置了一个监控器，跟踪 10 分钟内容器重启的次数。如果在这段时间内重启超过 3 次，容器的健康状态将设置为 "正在恶化"，表明可能存在需要调查的问题。

=== 服务可用端点

必须确保您的服务可供用户使用和访问。为了监控这一点，我们设置了一项检查，以验证服务是否至少有一个端点可用。端点是实现分布式系统中不同组件之间通信的网络地址，它们必须可用，服务才能正常运行。
如果在过去 10 分钟内出现可用端点为零的情况，监控器将保持偏离状态，表明服务可能存在问题需要解决。
要了解完整的监控器定义，请查看详细信息。

=== 服务期限

监控服务器和用户跨度的持续时间。当持续时间的第 95 百分位数大于阈值（默认为 5000 毫秒）时，监视器处于偏离状态。该监视器支持通过xref:/use/alerting/k8s-override-monitor-arguments.adoc[监视器参数重载]来覆盖设置。

=== 服务跨度误差比

Kubernetes 服务中处于错误状态的服务器和消费者跨度的百分比。该监视器支持通过xref:/use/alerting/k8s-override-monitor-arguments.adoc[监视器参数重载]来覆盖设置。

=== 有状态设置所需的副本

满足状态集所需的副本数量非常重要。StatefulSets 用于管理有状态应用程序，需要特定数量的副本才能正常运行。

为了监控这一点，SUSE Observability 设置了一项检查，以验证可用副本是否与所需副本数量相匹配。该检查只会应用于所需复制数大于零的有状态集。

* 如果可用副本的数量少于预期数量，监控器就会发出 "DEVIATING "健康状态信号，表明状态集可能存在问题。
* 如果可用副本的数量为零，监控器将发出 CRITICAL 健康状态信号，表明 StatefulSet 完全无法运行。

=== 不可调用节点

如果在 Kubernetes 中遇到 "NodeNotSchedulable"（节点不可调度）事件，这意味着 Kubernetes 调度器由于某些限制或节点问题而无法将 pod 放在特定节点上。当调度程序无法根据 pod 的资源需求和其他限制条件找到合适的节点来运行 pod 时，就会发生该事件。

=== 集群的综合健康状况

集群本身没有健康。但是，集群是由少数几个组件构建而成的，其中一些组件对正常运行至关重要。监控器汇总这些组件的状态：

* kube-system "命名空间中的所有 pod
* 所有节点，然后取最关键的健康状态。

=== 派生工作负载健康状态（部署、DaemonSet、ReplicaSet、StatefulSet）

监控器会汇总所有最重要依赖关系的状态，然后根据直接观察结果（如度量指标）返回最关键的健康状态。
这种方法可确保健康信号从低级技术组件（如 Pod）传播到高级逻辑组件，但只有在组件本身缺乏可观察到的健康状态时才会传播。
要有效使用该监视器，请确保禁用以下部分或全部健康检查：

* 部署所需的副本
* 守护进程设置所需的副本
* 所需的副本集
* 所需的 StatefulSet 复制

如果逻辑组件没有直接监控器，则可以使用xref:/use/alerting/k8s-derived-state-monitors.adoc[派生状态监控器]功能，根据其依赖的技术组件推断其健康状况。

== 另见

* xref:/use/alerting/k8s-monitors.adoc[监视器]
